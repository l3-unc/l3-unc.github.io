# This file contains the list of all publications
# Publications will be sorted by the date field.
# For conference publications, make the day the date of conference.

# Below is a documented template. You can also copy and edit one of the other papers.
# - title: -- The paper title
#   image: -- An image from your paper. This should be added to images/pubpic
#   description: -- Your abstract (or a small portion from it)  ((**** Please make sure there are no double quotes besides the start and end of the abstract. Replace any such instance inside the abstract with a single quote.))
#   authors: -- List of author names. For members of the lab they must match people.yaml
#      - Firstname Lastname
#      - show: Firstname Lastname* -- equal contribution can be marked by the show/link feature
#        link: Firstname Lastname
#      - show: Firstname Lastname*
#        link: Firstname Lastname
#  venue: -- ArXiv for pre-prints. Alternative, the conference/journal name without year.
#  date: YYYY-MM-DD -- For conference publications, make the day the date of conference.
#  links: -- Any left-side is valid, the right-side must be a link. Some examples below:
#    pdf : https://arxiv.org/pdf/{id}.pdf [[[[[MANDATORY]]]]]
#    arXiv: https://arxiv.org/abs/{id}
#    openreview: https://openreview.net/forum?id={id}
#    code: https://github.com/{username}/{id} -- Link to github
#  highlight: 0/1 If you want to showcase your work on the the Recent Work section
#  topics: -- Add relevant tags for the publication in order to make it easily discoverable. (min 1, max 3)
#     - {topic 1}
#     - {topic 2}
#     - {topic 3}




- title: "DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers"
  image: discern.png
  description: Machine learning classifiers often exhibit systematic biases due to dataset artifacts or class imbalances. DISCERN is a framework that generates natural language explanations for these biases, using an interactive loop between two large language models—one that identifies error patterns and another that refines them. The explanations improve classifier debugging and can be used to augment training data through synthetic instances or active learning. DISCERN consistently improves classification accuracy and helps humans interpret systematic biases 25% more effectively than cluster-based methods.
  authors: 
    - Rakesh R Menon
    - Shashank Srivastava
  date: 2024-11-12
  venue: Proceedings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: https://aclanthology.org/2024.emnlp-main.1091.pdf
    code:  https://github.com/rrmenon10/DISCERN
  topics: 
    - "Learning and Language"
    - "Fairness & Social Applications"
    - "Learning from Limited Labels"
  highlight: 1


- title: "Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion"
  image: fuse-to-forget.png
  description: Model fusion research aims to aggregate the knowledge of multiple individual models to enhance performance by combining their weights. In this work, we study the inverse problem -- investigating whether model fusion can be used to reduce unwanted knowledge. We investigate the effects of model fusion in three scenarios: the learning of shortcuts, social biases, and memorization of training data in fine-tuned language models. Through experiments covering classification and generation tasks, our analysis highlights that shared knowledge among models is enhanced during model fusion, while unshared knowledge is usually forgotten. Based on this observation, we demonstrate the potential of model fusion as a debiasing tool and showcase its efficacy in addressing privacy concerns associated with language models.
  authors: 
    - Kerem Zaman
    - Leshem Chosen
    - Shashank Srivastava
  date: 2024-11-12
  venue: Proceedings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: https://aclanthology.org/2024.emnlp-main.1045.pdf
    code:  https://github.com/KeremZaman/FuseToForget
  topics: 
    - "Learning and Language"
    - "Fairness & Social Applications"
  highlight: 1

- title: "SOCIALGAZE: Improving the Integration of Human Social Norms in Large Language Models"
  image: socialgaze.png
  description: Large language models struggle to align with human social norms, particularly when evaluating social acceptability in everyday situations. SOCIALGAZE is a multi-step prompting framework that improves LLMs' reasoning by encouraging them to verbalize social scenarios from multiple perspectives before making judgments. Experiments on social conflict narratives from the r/AITA subreddit show that SOCIALGAZE improves model alignment with human judgments by up to 11 F1 points. The study also uncovers several interesting biases in LLM social acceptability judgments -- for example, women are much less likely than men to be called out on r/AITA.
  authors: 
    - Anvesh Rao Vijjini
    - Rakesh R Menon
    - Jiayi Fu
    - Shashank Srivastava
    - Snigdha Chaturvedi
  date: 2024-11-12
  venue: Findings of Empirical Methods in Natural Language Processing (EMNLP Findings)
  links:
    pdf: https://aclanthology.org/2024.findings-emnlp.962.pdf
    code:  https://github.com/nvshrao/social_gaze
  topics: 
    - "Fairness & Social Applications"
  highlight: 1

- title: "Online Reinforcement Learning-Based Pedagogical Planning for Narrative-Centered Learning Environments"
  image: ncl.png
  description: Adaptive learning environments benefit from reinforcement learning-based pedagogical planners, but data scarcity limits their effectiveness. This paper introduces INSIGHT, an online RL framework that simulates student interactions in narrative-centered learning environments to train pedagogical policies dynamically. INSIGHT leverages a simulated student agent and a deep Q-learning-based planner to optimize educational interventions. Results show that online RL outperforms offline RL approaches in generating effective teaching policies, making INSIGHT a promising tool for AI-driven personalized learning.
  authors: 
    - Fahmid Morshed Fahid
    - Jonathan Rowe
    - Yeojin Kim
    - Shashank Srivastava
    - James Lester
  date: 2024
  venue: AAAI Conference on Artificial Intelligence (AAAI-24)
  links:
    pdf: https://ojs.aaai.org/index.php/AAAI/article/view/30365
  topics: 
    - "Miscellaneous"
  highlight: 0


- title: "MaNtLE: Model-agnostic Natural Language Explainer"
  image: mantle.jpg
  description: Understanding the internal reasoning behind the predictions of machine learning systems is increasingly vital, given their rising adoption and acceptance. While previous approaches, such as LIME, generate algorithmic explanations by attributing importance to input features for individual examples, recent research indicates that practitioners prefer examining language explanations that explain sub-groups of examples (Lakkaraju et al., 2022). In this paper, we introduce MaNtLE, a model-agnostic natural language explainer that analyzes multiple classifier predictions and generates faithful natural language explanations of classifier rationale for structured classification tasks. MaNtLE uses multi-task training on thousands of synthetic classification tasks to generate faithful explanations. Simulated user studies indicate that, on average, MaNtLE-generated explanations are at least 11% more faithful compared to LIME and Anchors explanations across three tasks. Human evaluations demonstrate that users can better predict model behavior using explanations from MaNtLE compared to other techniques.
  authors: 
    - Rakesh R Menon
    - Kerem Zaman
    - Shashank Srivastava
  date: 2023-12-06
  venue: Proceedings of Empirical Methods in Natural Language Processing (EMNLP)
  links: 
    pdf: /data/pdfs/MaNtLE_menon23.pdf
    arxiv:  https://arxiv.org/abs/2305.12995
    code:  https://github.com/rrmenon10/MaNtLE
  topics: 
    - "Learning and Language"
  highlight: 1

- title: "Identifying and Manipulating the Personality Traits of Language Models"
  image: personality_traits.jpg
  description: Psychology research has long explored aspects of human personality such as extroversion, agreeableness and emotional stability. Categorizations like the 'Big Five' personality traits are commonly used to assess and diagnose personality types. In this work, we explore the question of whether the perceived personality in language models is exhibited consistently in their language generation. For example, is a language model such as GPT2 likely to respond in a consistent way if asked to go out to a party? We also investigate whether such personality traits can be controlled. We show that when provided different types of contexts (such as personality descriptions, or answers to diagnostic questions about personality traits), language models such as BERT and GPT2 can consistently identify and reflect personality markers in those contexts. This behavior illustrates an ability to be manipulated in a highly predictable way, and frames them as tools for identifying personality traits and controlling personas in applications such as dialog systems. We also contribute a crowd-sourced data-set of personality descriptions of human subjects paired with their "Big Five" personality assessment data, and a data-set of personality descriptions collated from Reddit.
  authors: 
    - Graham Caron
    - Shashank Srivastava
  date: 2023-12-06
  venue: Findings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: /data/pdfs/personality_traits_caron23.pdf
    arxiv:  https://arxiv.org/abs/2212.10276
  topics: 
    - "Fairness and Social Applications"
    - "Datasets and Benchmarks"
  highlight: 1

  - title: "Pragmatic Reasoning Unlocks Quantifier Semantics for Foundation Models"
  image: presque.jpg
  description: Generalized quantifiers (e.g., few, most) are used to indicate the proportions predicates are satisfied (for example, some apples are red). One way to interpret quantifier semantics is to explicitly bind these satisfactions with percentage scopes (e.g., 30%-40% of apples are red). This approach can be helpful for tasks like logic formalization and surface-form quantitative reasoning (Gordon and Schubert, 2010; Roy et al., 2015). However, it remains unclear if recent foundation models possess this ability, as they lack direct training signals. To explore this, we introduce QuRe, a crowd-sourced dataset of human-annotated generalized quantifiers in Wikipedia sentences featuring percentage-equipped predicates. We explore quantifier comprehension in language models using PRESQUE, a framework that combines natural language inference and the Rational Speech Acts framework. Experimental results on the HVD dataset and QuRe illustrate that PRESQUE, employing pragmatic reasoning, performs 20% better than a literal reasoning baseline when predicting quantifier percentage scopes, with no additional training required.
  authors: 
    - Yiyuan Li
    - Rakesh R Menon
    - Sayan Ghosh
    - Shashank Srivastava
  date: 2023-12-06
  venue: Proceedings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: https://arxiv.org/pdf/2311.04659.pdf
    arxiv:  https://arxiv.org/abs/2311.04659
    code:  https://github.com/Nativeatom/PRESQUE
  topics: 
    - "Learning and Language"
    - "Datasets and Benchmarks"
  highlight: 0

- title: "Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided Classifiers"
  image:
  description: Recent approaches have explored language-guided classifiers capable of classifying examples from novel tasks when provided with task-specific natural language explanations, instructions or prompts (Sanh et al., 2022; R. Menon et al., 2022). While these classifiers can generalize in zero-shot settings, their task performance often varies substantially between different language explanations in unpredictable ways (Lu et al., 2022; Gonen et al., 2022). Also, current approaches fail to leverage unlabeled examples that may be available in many scenarios. Here, we introduce TALC, a framework that uses data programming to adapt a language-guided classifier for a new task during inference when provided with explanations from multiple teachers and unlabeled test examples. Our results show that TALC consistently outperforms a competitive baseline from prior work by an impressive 9.3% (relative improvement). Further, we demonstrate the robustness of TALC to variations in the quality and quantity of provided explanations, highlighting its potential in scenarios where learning from multiple teachers or a crowd is involved.
  authors: 
    - Kangda Wei
    - Sayan Ghosh
    - Rakesh R Menon
    - Shashank Srivastava
  date: 2023-12-06
  venue: Findings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: https://arxiv.org/pdf/2311.07538.pdf
    arxiv:  https://arxiv.org/abs/2311.07538
    code:  https://github.com/WeiKangda/TALC
  topics: 
    - "Learning and Language"
  highlight: 0

- title: "Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel Active-Learning Architecture "
  image:
  description: Real-world domain experts (e.g., doctors) rarely annotate only a decision label in their day-to-day workflow without providing explanations. Yet, existing low-resource learning techniques, such as Active Learning (AL), that aim to support human annotators mostly focus on the label while neglecting the natural language explanation of a data point. This work proposes a novel AL architecture to support experts real-world need for label and explanation annotations in low-resource scenarios. Our AL architecture leverages an explanation-generation model to produce explanations guided by human explanations, a prediction model that utilizes generated explanations toward prediction faithfully, and a novel data diversity-based AL sampling strategy that benefits from the explanation annotations. Automated and human evaluations demonstrate the effectiveness of incorporating explanations into AL sampling and the improved human annotation efficiency and trustworthiness with our AL architecture. Additional ablation studies illustrate the potential of our AL architecture for transfer learning, generalizability, and integration with large language models (LLMs). While LLMs exhibit exceptional explanation-generation capabilities for relatively simple tasks, their effectiveness in complex real-world tasks warrants further in-depth study.
  authors: 
    - Bingsheng Yao
    - Ishan Jindal
    - Lucian Popa
    - Yannis Katsis
    - Sayan Ghosh
    - Lihong He
    - Yuxuan Lu
    - Shashank Srivastava
    - Yunyao Li
    - James Hendler
    - Dakuo Wang
  date: 2023-12-06
  venue: Findings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: https://arxiv.org/pdf/2305.12710.pdf
    arxiv:  https://arxiv.org/abs/2305.12710
  topics: 
    - "Active Learning"
  highlight: 0

- title: "LaSQuE: Improved Zero-Shot Classification from Explanations Through Quantifier Modeling and Curriculum Learning"
  image:
  description: A hallmark of human intelligence is the ability to learn new concepts purely from language. Several recent approaches have explored training machine learning models via natural language supervision. However, these approaches fall short in leveraging linguistic quantifiers (such as 'always' or 'rarely') and mimicking humans in compositionally learning complex tasks. Here, we present LaSQuE, a method that can learn zero-shot classifiers from language explanations by using three new strategies - (1) modeling the semantics of linguistic quantifiers in explanations (including exploiting ordinal strength relationships, such as 'always’ > ‘likely’), (2) aggregating information from multiple explanations using an attention-based mechanism, and (3) model training via curriculum learning
  authors: 
    - show: Sayan Ghosh*
      link: Sayan Ghosh
    - show: Rakesh R Menon*
      link: Rakesh R Menon
    - Shashank Srivastava
  date: 2023-07-10
  venue: Findings of Association for Computational Linguistics (ACL)
  links:
    pdf: https://aclanthology.org/2023.findings-acl.467.pdf
    arxiv:  https://arxiv.org/abs/2212.09104
    code:  https://github.com/sgdgp/LaSQuE
  topics: 
    - "Learning and Language"
  highlight: 0

- title: "What do Large Language Models Learn beyond Language? "
  image: nilm.jpg
  description: "In this paper, we investigate if pre-training on text also confers these models with helpful `inductive biases' for non-linguistic reasoning. On a set of 19 diverse non-linguistic tasks involving quantitative computations, recognizing regular expressions and reasoning over strings. We find that pretrained models significantly outper- form comparable non-pretrained neural mod- els. This remains true also in experiments with training non-pretrained models with fewer pa- rameters to account for model regularization effects."
  authors: 
    - Avinash Madasu
    - Shashank Srivastava
  date: 2022-12-07
  venue: Findings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: https://arxiv.org/pdf/2210.12302.pdf
    arxiv: https://arxiv.org/abs/2210.12302
    code: https://github.com/avinashsai/NILM
  highlight: 0
  topics:
    - "Learning and Language"

- title: "Compositional Generalization for Kinship Prediction through Data Augmentation"
  image: clutrr_kangda.jpg
  description: "Transformer-based models have shown promising performance in numerous NLP tasks. However, recent work has shown the limitation of such models in showing compositional generalization, which requires models to generalize to novel compositions of known concepts. In this work, we explore two strategies for compositional generalization on the task of kinship prediction from stories,(1) data augmentation and (2) predicting and using intermediate structured representation (in form of kinship graphs). Our experiments show that data augmentation boosts generalization performance by around 20% on average relative to a baseline model from prior work not using these strategies. However, predicting and using intermediate kinship graphs leads to a deterioration in the generalization of kinship prediction by around 50% on average relative to models that only leverage data augmentation."
  authors: 
    - Kangda Wei
    - Sayan Ghosh
    - Shashank Srivastava
  date: 2022-07-15
  venue: Proceedings of the 4th Workshop of Narrative Understanding (WNU)
  links:
    pdf: https://aclanthology.org/2022.wnu-1.2.pdf
    code: https://github.com/WeiKangda/ssd-clutrr
  highlight: 0
  topics:
    - "Learning from Limited Labels"

- title: "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models"
  image: bigbench.png
  description: "Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 442 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters."
  authors: 
    - Big-Bench Collaboration
  date: 2023-05-01
  venue: Transactions of Machine Learning Research (TMLR)
  links:
    openreview: https://openreview.net/forum?id=uyTL5Bvosj
    pdf: https://openreview.net/pdf?id=uyTL5Bvosj
    arxiv: https://arxiv.org/abs/2206.04615
    code: https://github.com/google/BIG-bench
    dataset: https://github.com/google/BIG-bench
  topics: 
    - "Learning and Language"
    - "Datasets and Benchmarks"
  highlight: 0

- title: "CLUES: A Benchmark for Learning Classifiers using Natural Language Explanations"
  image: clues.jpg
  description: Supervised learning has traditionally focused on inductive learning by observing labeled examples of a task. In contrast, humans have the ability to learn new concepts from language. Here, we explore learning zero-shot classifiers for structured data purely from language from natural language explanations as supervision. For this, we introduce CLUES, a benchmark consisting of a range of classification tasks over structured data along with natural language supervision in the form of explanations. 
  authors: 
    - show: Rakesh R Menon*
      link: Rakesh R Menon
    - show: Sayan Ghosh*
      link: Sayan Ghosh
    - Shashank Srivastava
  date: 2022-05-26
  venue: Proceedings of Association for Computational Linguistics (ACL)
  links:
    pdf: https://aclanthology.org/2022.acl-long.451.pdf
    arxiv:  https://arxiv.org/abs/2204.07142
    code: https://www.github.com/rrmenon10/ExEnt
    dataset: https://clues-benchmark.github.io/
  topics: 
    - "Learning and Language"
    - "Datasets and Benchmarks"
  highlight: 0

- title: "ePiC: Employing Proverbs in Context as a Benchmark for Abstract Language Understanding"
  image: epic.png
  description: "ePiC is a crowdsourced dataset of narratives for employing proverbs in context as a benchmark for abstract language understanding. The dataset provides fine-grained annotation of aligned spans between proverbs and narratives, and contains minimal lexical overlaps between narratives and proverbs, ensuring that models need to go beyond surface-level reasoning to succeed. The dataset is accompanied by three tasks : (1) proverb recommendation and alignment prediction, (2) narrative generation for a given proverb and topic, and (3) identifying narratives with similar motifs."
  authors: 
    - Sayan Ghosh
    - Shashank Srivastava
  date: 2022-05-26
  venue: Proceedings of Association for Computational Linguistics (ACL)
  links:
    pdf: https://aclanthology.org/2022.acl-long.276.pdf
    arxiv:  https://arxiv.org/abs/2109.06838
    code: https://github.com/sgdgp/epic
    dataset: https://epic-benchmark.github.io/
  topics: 
    - "Datasets and Benchmarks"
    - "Language Understanding, Reasoning, and Generation"
    - "Fairness and Social Applications"
  highlight: 0

- title: "Predicting Difficulty and Discrimination of Natural Language Questions"
  image: pred_irt.png
  description: "Our experiments show that it is possible to predict both difficulty and discrimination parameters for new questions, and these traits are correlated with features of questions, answers, and associated contexts. Our findings can have significant implications for the creation of new datasets and tests on the one hand and strategies such as active learning and curriculum learning on the other."
  authors:
    - Matthew Byrd
    - Shashank Srivastava
  date: 2022-05-26
  venue: Proceedings of Association for Computational Linguistics (ACL)
  links:
    pdf: https://aclanthology.org/2022.acl-short.15.pdf
    code: https://github.com/ByrdOfAFeather/pred_irt
    dataset: https://github.com/ByrdOfAFeather/pred_irt
  topics: 
    - "Language Understanding, Reasoning, and Generation"
    - "Datasets and Benchmarks"
  highlight: 0


- title: "Improving and Simplifying Pattern Exploiting Training"
  image: adapet.jpg
  description: Pattern Exploiting Training (PET) is a recent approach that leverages patterns for few-shot learning. However, PET uses task-specific unlabeled data. In this paper, we focus on few shot learning without any unlabeled data and introduce ADAPET, which modifies PET’s objective to provide denser supervision during fine-tuning. As a result, ADAPET outperforms PET on SuperGLUE without any task-specific unlabeled data.
  authors: 
    - Derek Tam*
    - show: Rakesh R Menon*
      link: Rakesh R Menon
    - Mohit Bansal
    - Shashank Srivastava
    - Colin Raffel
    
  date: 2021-11-07
  venue: Proceedings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: https://arxiv.org/pdf/2103.11955.pdf
    arxiv:  https://arxiv.org/abs/2103.11955
    code: https://www.github.com/rrmenon10/ADAPET
  highlight: 0
  topics:
    - "Learning from Limited Labels"

- title: "Adversarial Scrubbing of Demographic Information for Text Classification"
  image: adversarial_scrubber.png
  description: "Contextual representations learned by language models can often encode undesirable attributes, like demographic associations of the users, while being trained for an unrelated target task. We aim to scrub such undesirable attributes and learn fair representations while maintaining performance on the target task. In this paper, we present an adversarial learning framework 'Adversarial Scrubber' (ADS), to debias contextual representations. We perform theoretical analysis to show that our framework converges without leaking demographic information under certain conditions. We extend previous evaluation techniques by evaluating debiasing performance using Minimum Description Length (MDL) probing. Experimental evaluations on 8 datasets show that ADS generates representations with minimal information about demographic attributes while being maximally informative about the target task."
  authors: 
    - Somnath Basu Roy Chowdhury
    - Sayan Ghosh
    - Yiyuan Li
    - Junier B Oliva
    - Shashank Srivastava
    - Snigdha Chaturvedi

  date: 2021-11-07
  venue: Proceedings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: https://aclanthology.org/2021.emnlp-main.43.pdf
    arxiv: https://arxiv.org/abs/2109.08613
    code: https://github.com/brcsomnath/adversarial-scrubber
  topics:
    - "Fairness and Social Applications"
  highlight: 0
  
- title: "Mapping Language to Programs using Multiple Reward Components with Inverse Reinforcement Learning"
  image: irl_virtualhome.png
  description: "Mapping natural language instructions to programs that computers can process is a fundamental challenge. Existing approaches focus on likelihood-based training or using reinforcement learning to fine-tune models based on a single reward. In this paper, we pose program generation from language as Inverse Reinforcement Learning. We introduce several interpretable reward components and jointly learn (1) a reward function that linearly combines them, and (2) a policy for program generation. Fine-tuning with our approach achieves significantly better performance than competitive methods using Reinforcement Learning (RL). On the VirtualHome framework, we get improvements of up to 9.0% on the Longest Common Subsequence metric and 14.7% on recall-based metrics over previous work on this framework (Puig et al., 2018). The approach is data-efficient, showing larger gains in performance in the low-data regime. Generated programs are also preferred by human evaluators over an RL-based approach, and rated higher on relevance, completeness, and human-likeness."
  authors: 
    - Sayan Ghosh
    - Shashank Srivastava
    
  date: 2021-11-07
  venue: Findings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: https://aclanthology.org/2021.findings-emnlp.125.pdf
    arxiv: https://arxiv.org/abs/2110.00842
    code: https://github.com/sgdgp/VirtualHome_IRL
  topics:
    - "Neuro-symbolic Learning"
  highlight: 0

- title: "How Helpful is Inverse Reinforcement Learning for Table-to-Text Generation?"
  image: irl_table_to_text.png
  description: "Existing approaches for the Table-to-Text task suffer from issues such as missing information, hallucination and repetition. Many approaches to this problem use Reinforcement Learning (RL), which maximizes a single manually defined reward, such as BLEU. In this work, we instead pose the Table-to-Text task as Inverse Reinforcement Learning (IRL) problem. We explore using multiple interpretable unsupervised reward components that are combined linearly to form a composite reward function. The composite reward function and the description generator are learned jointly. We find that IRL outperforms strong RL baselines marginally. We further study the generalization of learned IRL rewards in scenarios involving domain adaptation. Our experiments reveal significant challenges in using IRL for this task."
  authors: 
    - show: Sayan Ghosh*
      link: Sayan Ghosh
    - show: Zheng Qi*
      link: Zheng Qi
    - Snigdha Chaturvedi
    - Shashank Srivastava
    
  date: 2021-08-02
  venue: Proceedings of Association for Computational Linguistics (ACL)
  links:
    pdf: https://aclanthology.org/2021.acl-short.11.pdf
    code: https://github.com/issacqzh/IRL_Table2Text
  topics:
    - "Language Understanding, Reasoning, and Generation"
  highlight: 0

- title: "PRover: Proof Generation for Interpretable Reasoning over Rules"
  image: prover.png
  description: "Recent work by Clark et al. (2020) shows that transformers can act as 'soft theorem provers' by answering questions over explicitly provided knowledge in natural language. In our work, we take a step closer to emulating formal theorem provers, by proposing PROVER, an interpretable transformer-based model that jointly answers binary questions over rule-bases and generates the corresponding proofs. Our model learns to predict nodes and edges corresponding to proof graphs in an efficient constrained training paradigm. During inference, a valid proof, satisfying a set of global constraints is generated. We conduct experiments on synthetic, hand-authored, and human-paraphrased rule-bases to show promising results for QA and proof generation, with strong generalization performance. First, PROVER generates proofs with an accuracy of 87%, while retaining or improving performance on the QA task, compared to RuleTakers (up to 6% improvement on zero-shot evaluation). Second, when trained on questions requiring lower depths of reasoning, it generalizes significantly better to higher depths (up to 15% improvement). Third, PROVER obtains near perfect QA accuracy of 98% using only 40% of the training data. However, generating proofs for questions requiring higher depths of reasoning becomes challenging, and the accuracy drops to 65% for 'depth 5', indicating significant scope for future work."
  authors: 
    - Swarnadeep Saha
    - Sayan Ghosh
    - Shashank Srivastava
    - Mohit Bansal
    
  date: 2020-11-17
  venue: Proceedings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: https://aclanthology.org/2020.emnlp-main.9.pdf
    arxiv: https://arxiv.org/abs/2010.02830
    code: https://github.com/swarnaHub/PRover
  topics:
    - "Language Understanding, Reasoning, and Generation"
  highlight: 0

- title: "A Topical graph-kernel for Link Prediction in Labeled Graphs"
  image: ""
  description: ""
  authors:
    - Snigdha Chaturvedi
    - Hal Daume III
    - Taesun Moon
    - Shashank Srivastava
  date: 2012-06-26
  venue: ICML Workshop on Mining and Learning with Graphs (MLG)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava13-graphkernel.pdf
  topics:
    - "Miscellaneous"
  highlight: 0

- title: "A Structured Distributional Semantic Model : Integrating Structure with Semantics"
  image: ""
  description: ""
  authors:
    - Kartik Goyal*
    - Sujay Kumar Jauhar*
    - Huiying Li*
    - Mrinmaya Sachan*
    - show: Shashank Srivastava*
      link: Shashank Srivastava
    - Eduard Hovy
  date: 2013-08-04
  venue: Workshop on Continuous Vector Space Models and their Compositionality, ACL
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava13-sdsmWorkshop.pdf
  topics:
    - "Syntax and Semantics"
  highlight: 0

- title: "Identifying Metaphorical Word Use with Tree Kernels"
  image: ""
  description: ""
  authors:
    - Dirk Hovy
    - Shashank Srivastava
    - Sujay Kumar Jauhar
    - Mrinmaya Sachan
    - Kartik Goyal
    - Huiying Li
    - Whitney Sanders
    - Eduard Hovy
  date: 2013-06-13
  venue: NAACL-HLT Meta4NLP Workshop
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava13-metaphor.pdf
  topics:
    - "Syntax and Semantics"
  highlight: 0

- title: "A Structured Distributional Semantic Model for Event Co-reference"
  image: ""
  description: ""
  authors:
    - Kartik Goyal*
    - Sujay Kumar Jauhar*
    - Huiying Li*
    - Mrinmaya Sachan*
    - show: Shashank Srivastava*
      link: Shashank Srivastava
    - Eduard Hovy
  date: 2013-08-04
  venue: Proceedings of the Association of Computational Linguistics (ACL)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava13-sdsm.pdf
  topics:
    - "Syntax and Semantics"
  highlight: 0

- title: "A Walk-based Semantically Enriched Tree Kernel Over Distributed Word Representations"
  image: ""
  description: ""
  authors:
    - Shashank Srivastava
    - Dirk Hovy
    - Eduard Hovy
  date: 2013-10-18
  venue: Proceedings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava13-treekernel.pdf
  topics:
    - "Syntax and Semantics"
  highlight: 0

- title: "Spatial Compactness meets Topical Consistency: Jointly modeling link and content for community detection"
  image: ""
  description: ""
  authors:
    - Mrinmaya Sachan
    - Avinava Dubey
    - Shashank Srivastava
    - Eric P Xing
    - Eduard Hovy
  date: 2014-02-24
  venue: Proceedings of Web Search and Data Mining (WSDM)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava14-community.pdf
  topics:
    - "Miscellaneous"
  highlight: 0

- title: "Vector space semantics with frequency-driven motifs"
  image: ""
  description: ""
  authors:
    - Shashank Srivastava
    - Eduard Hovy
  date: 2014-05-06
  venue: Proceedings of the Association of Computational Linguistics (ACL)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava14-motifs.pdf
  topics:
    - "Syntax and Semantics"
  highlight: 0

- title: "CMU-ML System for KBP Cold Start Slot Filling"
  image: ""
  description: ""
  authors:
    - Bryan Kisiel
    - Bill McDowell
    - Matt Gardner
    - Ndapandula Nakashole
    - Emmanouil A. Platanios
    - Abulhair Saparov
    - Shashank Srivastava
    - Derry Wijaya
    - Tom Mitchell
  date: 2015-11-16
  venue: Proceedings of the Text Analysis Conference (TAC)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava15-KBP.pdf
  topics:
    - "Syntax and Semantics"
  highlight: 0

- title: "CMUML Micro-Reader System for KBP 2016 Cold Start Slot Filling, Event Nugget Detection, and Event Argument Linking"
  image: ""
  description: ""
  authors:
    - Bishan Yang
    - Ndapandula Nakashole
    - Bryan Kisiel
    - Emmanouil A. Platanios
    - Abulhair Saparov
    - Shashank Srivastava
    - Derry Wijaya
    - Tom Mitchell
  date: 2016-11-14
  venue: Proceedings of the Text Analysis Conference (TAC)
  links:
    pdf: https://tac.nist.gov/publications/2016/participant.papers/TAC2016.CMUML.proceedings.pdf
  topics:
    - "Syntax and Semantics"
  highlight: 0

- title: "Modeling Evolving Relationships Between Characters in Literary Novel"
  image: ""
  description: ""
  authors:
    - Snigdha Chaturvedi
    - Shashank Srivastava
    - Hal Daume III
    - Chris Dyer
  date: 2016-02-12
  venue: Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava16-evolving.pdf
  topics:
    - "Fairness and Social Applications"
  highlight: 0

- title: "Inferring Interpersonal Relations in Narrative Summaries"
  image: ""
  description: ""
  authors:
    - Shashank Srivastava
    - Snigdha Chaturvedi
    - Tom Mitchell
  date: 2016-02-12
  venue: Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava16-inferring.pdf
  topics:
    - "Fairness and Social Applications"
    - "Datasets and Benchmarks"
  highlight: 0

- title: "Parsing Natural Language Conversations with Contextual Cues"
  image: ""
  description: ""
  authors:
    - Shashank Srivastava
    - Amos Azaria
    - Tom Mitchell
  date: 2017-08-19
  venue: Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava17-conversations.pdf
  topics:
    - "Neuro-symbolic Learning"
    - "Datasets and Benchmarks"
  highlight: 0

- title: "Joint Concept Learning and Semantic Parsing from Natural Language Explanations"
  image: ""
  description: ""
  authors:
    - Shashank Srivastava
    - Igor Labutov
    - Tom Mitchell
  date: 2017-09-07
  venue: Proceedings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava17-jointLNL.pdf
  topics:
    - "Learning and Language"
    - "Learning from Limited Labels"
    - "Datasets and Benchmarks"
  highlight: 0

- title: "Learning Classifiers from Declarative Language"
  image: ""
  description: ""
  authors:
    - Shashank Srivastava
    - Igor Labutov
    - Tom Mitchell
  date: 2017-12-07
  venue: NeurIPS Workshop on Learning from Limited Data
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava17-lldworkshop.pdf
  topics:
    - "Learning and Language"
    - "Learning from Limited Labels"
  highlight: 0

- title: "Where have I heard this story before? : Identifying Narrative Similarity in Movie Remakes"
  image: ""
  description: ""
  authors:
    - Snigdha Chaturvedi
    - Shashank Srivastava
    - Dan Roth
  date: 2018-06-01
  venue: Proceedings of the North Americal Chapter of Association of Computational Linguistics (NAACL)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava18-remakes.pdf
  topics:
    - "Fairness and Social Applications"
    - "Datasets and Benchmarks"
  highlight: 0

- title: "LIA: A Natural Language Programmable Personal Assistant"
  image: ""
  description: ""
  authors:
    - Igor Labutov
    - Shashank Srivastava
    - Tom Mitchell
  date: 2018-10-31
  venue: Systems Demo, Proceedings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava18-LiA.pdf
  topics:
    - "Learning and Language"
  highlight: 0

- title: "Zero-shot Learning of Classifiers from Natural Language Quantification"
  image: ""
  description: ""
  authors:
    - Shashank Srivastava
    - Igor Labutov
    - Tom Mitchell
  date: 2018-07-15
  venue: Proceedings of the Association of Computational Linguistics (ACL)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava18-lnq.pdf
  topics:
    - "Learning and Language"
    - "Learning from Limited Labels"
  highlight: 0

- title: "A Spatial Model for Extracting and Visualizing Latent Discourse Structure in Text"
  image: ""
  description: ""
  authors:
    - Shashank Srivastava
    - Nebojsa Jojic
  date: 2018-07-15
  venue: Proceedings of the Association of Computational Linguistics (ACL)
  links:
    pdf: http://www.cs.cmu.edu/~shashans/papers/srivastava18-spatial.pdf
  topics:
    - "Syntax and Semantics"
  highlight: 0

- title: "Learning to Ask for Conversational Machine Learning"
  image: ""
  description: ""
  authors:
    - Shashank Srivastava
    - Igor Labutov
    - Tom Mitchell
  date: 2019-11-03
  venue: Proceedings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: https://aclanthology.org/D19-1426.pdf
  topics:
    - "Learning and Language"
    - "Learning from Limited Labels"
  highlight: 0

- title: "An Agent for Learning New Natural Language Commands"
  image: ""
  description: ""
  authors:
    - Amos Azaria
    - Shashank Srivastava
    - Jayant Krishnamurthy
    - Igor Labutov
    - Tom Mitchell
  date: 2020-01-01
  venue: Journal of Autonomous Agents and Multi-Agent Systems (JAAMAS)
  links:
    link: https://link.springer.com/article/10.1007/s10458-019-09425-x
  topics:
    - "Learning and Language"
    - "Learning from Limited Labels"
  highlight: 0

- title: "Learning Web-based procedures by Reasoning over Explanations and Demonstrations in Context"
  image: ""
  description: ""
  authors:
    - Shashank Srivastava
    - Oleksandr Polozov
    - Nebojsa Jojic
    - Christopher Meek
  date: 2020-07-06
  venue: Proceedings of the Association of Computational Linguistics (ACL)
  links:
    pdf: https://aclanthology.org/2020.acl-main.684.pdf
    dataset: https://aka.ms/Web-D-E
  topics:
    - "Learning and Language"
    - "Learning from Limited Labels"
    - "Neuro-symbolic Learning"
    - "Datasets and Benchmarks"
  highlight: 0

- title: "Does Social Pressure Drive Persuasion in Online Fora?"
  image: "cmv.jpg"
  description: ""
  authors:
    - Ayush Jain
    - Shashank Srivastava
  date: 2021-11-07
  venue: Proceedings of Empirical Methods in Natural Language Processing (EMNLP)
  links:
    pdf: https://aclanthology.org/2021.emnlp-main.725.pdf
  topics:
    - "Fairness and Social Applications"
  highlight: 1
